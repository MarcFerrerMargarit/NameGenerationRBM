{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM Name Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from GridEncoder import GridEncoder\n",
    "import Utils\n",
    "from ShortTextCodec import ShortTextCodec, BinomialShortTextCodec\n",
    "from RBM import BernoulliRBM\n",
    "import Sampling\n",
    "import sample\n",
    "import sys\n",
    "import colorama\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BIASED_PRIOR = 0\n",
    "\n",
    "class CharBernoulli(BernoulliRBM):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        codec is the ShortTextCodec used to create the vectors being fit. The\n",
    "        most important function of the codec is as a proxy to the shape of the\n",
    "        softmax units in the visible layer (if you're using the CharBernoulliRBMSoftmax\n",
    "        subclass). It's also used to decode and print\n",
    "        fantasy particles at the end of each epoch.\n",
    "        \"\"\"\n",
    "        # Attaching this to the object is really helpful later on when models\n",
    "        # are loaded from pickle in visualize.py and sample.py\n",
    "        self.codec = kwargs.pop(\"codec\")\n",
    "        self.softmax_shape = codec.shape()\n",
    "        # Old-style class :(\n",
    "        BernoulliRBM.__init__(self, **kwargs)\n",
    "\n",
    "    def wellness_check(self, epoch, duration, train, validation):\n",
    "        BernoulliRBM.wellness_check(self, epoch, duration, train, validation)\n",
    "        fantasy_samples = '|'.join([self.codec.decode(vec) for vec in\n",
    "                                    self._sample_visibles(self.h_samples_[:3], temperature=0.1)])\n",
    "        print (\"Fantasy samples: {}\".format(fantasy_samples))\n",
    "\n",
    "    def corrupt(self, v):\n",
    "        n_softmax, n_opts = self.softmax_shape\n",
    "        # Select a random index in to the indices of the non-zero values of each input\n",
    "        # TODO: In the char-RBM case, if I wanted to really challenge the model, I would avoid selecting any\n",
    "        # trailing spaces here. Cause any dumb model can figure out that it should assign high energy to\n",
    "        # any instance of /  [^ ]/\n",
    "        meta_indices_to_corrupt = self.rng_.randint(0, n_softmax, v.shape[0]) + np.arange(0, n_softmax * v.shape[0], n_softmax)\n",
    "\n",
    "        # Offset these indices by a random amount (but not 0 - we want to actually change them)\n",
    "        offsets = self.rng_.randint(1, n_opts, v.shape[0])\n",
    "        # Also, do some math to make sure we don't \"spill over\" into a different softmax.\n",
    "        # E.g. if n_opts=5, and we're corrupting index 3, we should choose offsets from {-3, -2, -1, +1}\n",
    "        # 1-d array that matches with meta_i_t_c but which contains the indices themselves\n",
    "        indices_to_corrupt = v.indices[meta_indices_to_corrupt]\n",
    "        # Sweet lucifer\n",
    "        offsets = offsets - (n_opts * (((indices_to_corrupt % n_opts) + offsets.ravel()) >= n_opts))\n",
    "\n",
    "        v.indices[meta_indices_to_corrupt] += offsets\n",
    "        return v, (meta_indices_to_corrupt, offsets)\n",
    "\n",
    "    def uncorrupt(self, visibles, state):\n",
    "        mitc, offsets = state\n",
    "        visibles.indices[mitc] -= offsets\n",
    "        \n",
    "class CharBernoulliSoftmax(CharBernoulli):\n",
    "    def __init__(self,**kwargs):\n",
    "        CharBernoulli.__init__(self, **kwargs)\n",
    "        \n",
    "    def _sample_visibles(self, h, temperature=1.0):\n",
    "        \"\"\"Sample from the distribution P(v|h). This obeys the softmax constraint\n",
    "        on visible units. i.e. sum(v) == softmax_shape[0] for any visible\n",
    "        configuration v.\n",
    "\n",
    "        h : array-like, shape (n_samples, n_components)\n",
    "            Values of the hidden layer to sample from.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        v : array-like, shape (n_samples, n_features)\n",
    "            Values of the visible layer.\n",
    "        \"\"\"\n",
    "        p = np.dot(h, self.components_/temperature)\n",
    "        p += self.intercept_visible_/(min(1.0, temperature) if BIASED_PRIOR else temperature)\n",
    "        nsamples, nfeats = p.shape\n",
    "        reshaped = np.reshape(p, (nsamples,) + self.softmax_shape)\n",
    "        return Utils.softmax_and_sample(reshaped).reshape((nsamples, nfeats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codec_kls = ShortTextCodec\n",
    "codec = codec_kls('',10,0,True,False)\n",
    "codec.debug_description()\n",
    "model_kwargs = {'codec': codec,\n",
    "                        'n_components': 200,\n",
    "                        'learning_rate': 0.1,\n",
    "                        'lr_backoff': False,\n",
    "                        'n_iter': 20,\n",
    "                        'verbose': 1,\n",
    "                        'batch_size': 10,\n",
    "                        'weight_cost': 0.0001,\n",
    "                        }\n",
    "kls = CharBernoulliSoftmax\n",
    "rbm = kls(**model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Names File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28429, 530) (28429, 530)\n"
     ]
    }
   ],
   "source": [
    "vecs = Utils.vectors_from_txtfile(\"./names.txt\", codec)\n",
    "train, validation = train_test_split(vecs, test_size=0.5)\n",
    "print(train.shape,validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CharBernoulliSoftmax] Iteration 1/20\tt = 10.38s\n",
      "Pseudo-log-likelihood sum: -41056.42\tAverage per instance: -1.44\n",
      "E(vali):\t-27.73\tE(train):\t-27.72\tdifference: -0.01\n",
      "Fantasy samples: Sareieee$$|Seeeleen$$|Sarl$$$$$$\n",
      "[CharBernoulliSoftmax] Iteration 2/20\tt = 11.17s\n",
      "Pseudo-log-likelihood sum: -37722.40\tAverage per instance: -1.33\n",
      "E(vali):\t-24.23\tE(train):\t-24.23\tdifference: 0.00\n",
      "Fantasy samples: Marerla$$$|Collinger$|Born$$$$$$\n",
      "[CharBernoulliSoftmax] Iteration 3/20\tt = 13.96s\n",
      "Pseudo-log-likelihood sum: -34612.72\tAverage per instance: -1.22\n",
      "E(vali):\t-23.19\tE(train):\t-23.23\tdifference: 0.03\n",
      "Fantasy samples: Marth$$$$$|Marring$$$|Marke$$$$$\n",
      "[CharBernoulliSoftmax] Iteration 4/20\tt = 11.15s\n",
      "Pseudo-log-likelihood sum: -32326.75\tAverage per instance: -1.14\n",
      "E(vali):\t-22.46\tE(train):\t-22.53\tdifference: 0.06\n",
      "Fantasy samples: Sonne$$$$$|Eller$$$$$|Bronanerl$\n",
      "[CharBernoulliSoftmax] Iteration 5/20\tt = 9.96s\n",
      "Pseudo-log-likelihood sum: -30894.13\tAverage per instance: -1.09\n",
      "E(vali):\t-23.74\tE(train):\t-23.81\tdifference: 0.07\n",
      "Fantasy samples: Lelen$$$$$|Kittermon$|Frinel$$$$\n",
      "[CharBernoulliSoftmax] Iteration 6/20\tt = 10.13s\n",
      "Pseudo-log-likelihood sum: -28717.62\tAverage per instance: -1.01\n",
      "E(vali):\t-23.21\tE(train):\t-23.32\tdifference: 0.11\n",
      "Fantasy samples: Coranek$$$|Elettern$$|Strall$$$$\n",
      "[CharBernoulliSoftmax] Iteration 7/20\tt = 10.52s\n",
      "Pseudo-log-likelihood sum: -28161.59\tAverage per instance: -0.99\n",
      "E(vali):\t-24.32\tE(train):\t-24.45\tdifference: 0.13\n",
      "Fantasy samples: Mardin$$$$|Iee$$$$$$$|Lameliage$\n",
      "[CharBernoulliSoftmax] Iteration 8/20\tt = 11.09s\n",
      "Pseudo-log-likelihood sum: -28747.94\tAverage per instance: -1.01\n",
      "E(vali):\t-23.73\tE(train):\t-23.91\tdifference: 0.17\n",
      "Fantasy samples: Bouthand$$|Shill$$$$$|Rorne$$$$$\n",
      "[CharBernoulliSoftmax] Iteration 9/20\tt = 14.16s\n",
      "Pseudo-log-likelihood sum: -26548.51\tAverage per instance: -0.93\n",
      "E(vali):\t-24.65\tE(train):\t-24.83\tdifference: 0.18\n",
      "Fantasy samples: Lever$$$$$|Lanertt$$$|Shafler$$$\n",
      "[CharBernoulliSoftmax] Iteration 10/20\tt = 26.36s\n",
      "Pseudo-log-likelihood sum: -25688.33\tAverage per instance: -0.90\n",
      "E(vali):\t-26.47\tE(train):\t-26.66\tdifference: 0.19\n",
      "Fantasy samples: Her$$$$$$$|Landttend$|Wilkaare$$\n",
      "[CharBernoulliSoftmax] Iteration 11/20\tt = 15.20s\n",
      "Pseudo-log-likelihood sum: -25007.88\tAverage per instance: -0.88\n",
      "E(vali):\t-25.71\tE(train):\t-25.95\tdifference: 0.24\n",
      "Fantasy samples: Lines$$$$$|Amrry$$$$$|Stade$$$$$\n",
      "[CharBernoulliSoftmax] Iteration 12/20\tt = 23.97s\n",
      "Pseudo-log-likelihood sum: -25647.42\tAverage per instance: -0.90\n",
      "E(vali):\t-26.06\tE(train):\t-26.31\tdifference: 0.25\n",
      "Fantasy samples: Shivick$$$|Hurphald$$|Ellinger$$\n",
      "[CharBernoulliSoftmax] Iteration 13/20\tt = 23.76s\n",
      "Pseudo-log-likelihood sum: -25729.36\tAverage per instance: -0.91\n",
      "E(vali):\t-27.88\tE(train):\t-28.13\tdifference: 0.25\n",
      "Fantasy samples: Bicken$$$$|Dickle$$$$|Gallon$$$$\n",
      "[CharBernoulliSoftmax] Iteration 14/20\tt = 25.44s\n",
      "Pseudo-log-likelihood sum: -25635.79\tAverage per instance: -0.90\n",
      "E(vali):\t-26.15\tE(train):\t-26.45\tdifference: 0.30\n",
      "Fantasy samples: Mersort$$$|Burinesii$|Trites$$$$\n",
      "[CharBernoulliSoftmax] Iteration 15/20\tt = 24.70s\n",
      "Pseudo-log-likelihood sum: -25163.61\tAverage per instance: -0.89\n",
      "E(vali):\t-26.78\tE(train):\t-27.08\tdifference: 0.30\n",
      "Fantasy samples: Saddres$$$|Harsia$$$$|Perrie$$$$\n",
      "[CharBernoulliSoftmax] Iteration 16/20\tt = 29.63s\n",
      "Pseudo-log-likelihood sum: -23519.94\tAverage per instance: -0.83\n",
      "E(vali):\t-27.69\tE(train):\t-28.03\tdifference: 0.33\n",
      "Fantasy samples: Merris$$$$|Don$$$$$$$|Shares$$$$\n",
      "[CharBernoulliSoftmax] Iteration 17/20\tt = 19.38s\n",
      "Pseudo-log-likelihood sum: -22860.12\tAverage per instance: -0.80\n",
      "E(vali):\t-27.17\tE(train):\t-27.50\tdifference: 0.33\n",
      "Fantasy samples: Luffe$$$$$|Vallies$$$|Gos$$$$$$$\n",
      "[CharBernoulliSoftmax] Iteration 18/20\tt = 10.94s\n",
      "Pseudo-log-likelihood sum: -23846.49\tAverage per instance: -0.84\n",
      "E(vali):\t-27.60\tE(train):\t-27.94\tdifference: 0.34\n",
      "Fantasy samples: Micews$$$$|Branc$$$$$|Cearnette$\n",
      "[CharBernoulliSoftmax] Iteration 19/20\tt = 10.47s\n",
      "Pseudo-log-likelihood sum: -23861.90\tAverage per instance: -0.84\n",
      "E(vali):\t-28.10\tE(train):\t-28.49\tdifference: 0.39\n",
      "Fantasy samples: Silingerg$|Statt$$$$$|Vinala$$$$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharBernoulliSoftmax()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm.fit(train,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rydser      \n",
      "Cobp        \n",
      "Elihan      \n",
      "Amirh       \n",
      "Haon        \n",
      "Hora        \n",
      "Ebi         \n",
      "Idul        \n",
      "Adki        \n",
      "Cyzel       \n",
      "Bieh        \n",
      "Adag        \n",
      "Finn        \n",
      "Iavan       \n",
      "Ten         \n",
      "Menterberg  \n",
      "Eso         \n",
      "Ajrr        \n",
      "Weover      \n",
      "Ecoma       \n",
      "Iner        \n",
      "Meag        \n",
      "Art         \n",
      "Felkue      \n",
      "Shum        \n",
      "Klox        \n",
      "Ligek       \n",
      "Akhley      \n",
      "Naldr       \n",
      "Enae        \n",
      "Final energy: -33.61 (stdev=2.90)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLES = []\n",
    "def horizontal_cb(strings, i, energy=None):\n",
    "    global SAMPLES\n",
    "    if energy is not None:\n",
    "        SAMPLES.append(zip(strings, energy))\n",
    "    else:\n",
    "        SAMPLES.append(strings)\n",
    "def print_columns(maxlen):\n",
    "    col_width = maxlen+2\n",
    "    for fantasy_index in range(len(SAMPLES[0])):\n",
    "        particles = [s[fantasy_index] for s in SAMPLES]\n",
    "        print (\"\".join(s[fantasy_index].ljust(col_width) for s in SAMPLES))\n",
    "sample_indices = [1000-1]\n",
    "kwargs = dict(start_temp=1.0, final_temp=1.0, sample_energy=False, \n",
    "                    callback=horizontal_cb)\n",
    "\n",
    "vis = Sampling.sample_model(rbm, 30, 1000, sample_indices, **kwargs)\n",
    "print_columns(rbm.codec.maxlen)\n",
    "fe = rbm._free_energy(vis)\n",
    "print('Final energy: {:.2f} (stdev={:.2f})\\n'.format(fe.mean(), fe.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spanish Name File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26088, 530) (26088, 530)\n"
     ]
    }
   ],
   "source": [
    "vecs = Utils.vectors_from_txtfile(\"./spanish.txt\", codec)\n",
    "train, validation = train_test_split(vecs, test_size=0.5)\n",
    "print(train.shape,validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing existing weights and biases\n",
      "[CharBernoulliSoftmax] Iteration 1/10\tt = 13.71s\n",
      "Pseudo-log-likelihood sum: -19258.85\tAverage per instance: -0.74\n",
      "E(vali):\t-37.71\tE(train):\t-37.82\tdifference: 0.12\n",
      "Fantasy samples: conruruear|sorantar$$|desgambear\n",
      "[CharBernoulliSoftmax] Iteration 2/10\tt = 16.22s\n",
      "Pseudo-log-likelihood sum: -16216.99\tAverage per instance: -0.62\n",
      "E(vali):\t-39.56\tE(train):\t-39.72\tdifference: 0.15\n",
      "Fantasy samples: resrar$$$$|reqriar$$$|crafentear\n",
      "[CharBernoulliSoftmax] Iteration 3/10\tt = 14.03s\n",
      "Pseudo-log-likelihood sum: -16578.11\tAverage per instance: -0.64\n",
      "E(vali):\t-38.99\tE(train):\t-39.10\tdifference: 0.11\n",
      "Fantasy samples: supodar$$$|aperronar$|embrenar$$\n",
      "[CharBernoulliSoftmax] Iteration 4/10\tt = 16.56s\n",
      "Pseudo-log-likelihood sum: -15322.08\tAverage per instance: -0.59\n",
      "E(vali):\t-41.39\tE(train):\t-41.60\tdifference: 0.21\n",
      "Fantasy samples: lamponear$|acotar$$$$|recar$$$$$\n",
      "[CharBernoulliSoftmax] Iteration 5/10\tt = 13.62s\n",
      "Pseudo-log-likelihood sum: -15067.42\tAverage per instance: -0.58\n",
      "E(vali):\t-43.93\tE(train):\t-44.04\tdifference: 0.11\n",
      "Fantasy samples: armondar$$|amorcar$$$|cacolizar$\n",
      "[CharBernoulliSoftmax] Iteration 6/10\tt = 13.22s\n",
      "Pseudo-log-likelihood sum: -13891.38\tAverage per instance: -0.53\n",
      "E(vali):\t-44.33\tE(train):\t-44.49\tdifference: 0.17\n",
      "Fantasy samples: caalinar$$|destrar$$$|rachar$$$$\n",
      "[CharBernoulliSoftmax] Iteration 7/10\tt = 13.80s\n",
      "Pseudo-log-likelihood sum: -15069.20\tAverage per instance: -0.58\n",
      "E(vali):\t-45.39\tE(train):\t-45.63\tdifference: 0.25\n",
      "Fantasy samples: acabarizar|rechudchar|dostojar$$\n",
      "[CharBernoulliSoftmax] Iteration 8/10\tt = 16.35s\n",
      "Pseudo-log-likelihood sum: -14832.82\tAverage per instance: -0.57\n",
      "E(vali):\t-46.54\tE(train):\t-46.68\tdifference: 0.14\n",
      "Fantasy samples: raunar$$$$|piestar$$$|riar$$$$$$\n",
      "[CharBernoulliSoftmax] Iteration 9/10\tt = 14.20s\n",
      "Pseudo-log-likelihood sum: -14153.50\tAverage per instance: -0.54\n",
      "E(vali):\t-51.72\tE(train):\t-52.09\tdifference: 0.37\n",
      "Fantasy samples: empurnear$|perear$$$$|entianar$$\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharBernoulliSoftmax()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm.fit(train,validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todurar     \n",
      "espurar     \n",
      "espurar     \n",
      "antumar     \n",
      "sucurar     \n",
      "encacar     \n",
      "traspar     \n",
      "zigurar     \n",
      "espurar     \n",
      "mizucar     \n",
      "escurar     \n",
      "espurar     \n",
      "endorar     \n",
      "empesar     \n",
      "empubar     \n",
      "esturar     \n",
      "escurar     \n",
      "visurar     \n",
      "eszurar     \n",
      "nequiar     \n",
      "estupar     \n",
      "lrandar     \n",
      "empelar     \n",
      "escurar     \n",
      "livurar     \n",
      "enturar     \n",
      "enhular     \n",
      "espurar     \n",
      "excorar     \n",
      "enlodar     \n",
      "Final energy: -65.09 (stdev=3.84)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLES = []\n",
    "def horizontal_cb(strings, i, energy=None):\n",
    "    global SAMPLES\n",
    "    if energy is not None:\n",
    "        SAMPLES.append(zip(strings, energy))\n",
    "    else:\n",
    "        SAMPLES.append(strings)\n",
    "def print_columns(maxlen):\n",
    "    col_width = maxlen+2\n",
    "    for fantasy_index in range(len(SAMPLES[0])):\n",
    "        particles = [s[fantasy_index] for s in SAMPLES]\n",
    "        print (\"\".join(s[fantasy_index].ljust(col_width) for s in SAMPLES))\n",
    "sample_indices = [1000-1]\n",
    "kwargs = dict(start_temp=1.0, final_temp=1.0, sample_energy=False, \n",
    "                    callback=horizontal_cb)\n",
    "\n",
    "vis = Sampling.sample_model(rbm, 30, 1000, sample_indices, **kwargs)\n",
    "print_columns(rbm.codec.maxlen)\n",
    "fe = rbm._free_energy(vis)\n",
    "print('Final energy: {:.2f} (stdev={:.2f})\\n'.format(fe.mean(), fe.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test with RBM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import inspect\n",
    "\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent =  currentdir + '\\RBM_Git'\n",
    "sys.path.insert(0,parent)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numexpr  as ne\n",
    "import profile\n",
    "import rbm as Rbm\n",
    "import pandas\n",
    "from random import randint\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "codec_kls = ShortTextCodec\n",
    "codec = codec_kls('',10,0,True,False)\n",
    "vecs = Utils.vectors_from_txtfile(\"./names.txt\", codec)\n",
    "visible_dim = vecs.shape[1]\n",
    "hidden_dim = 200\n",
    "epochs = 100\n",
    "K = 1\n",
    "lr = 0.1\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((530, 200), (530,), <rbm.RBM at 0x25bd93e9c88>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm_ = Rbm.RBM(visible_dim=visible_dim,\n",
    "               hidden_dim=hidden_dim,\n",
    "               seed=42,\n",
    "               mu=0, \n",
    "               sigma=0.3,\n",
    "               monitor_time=True)\n",
    "rbm_.W.shape, rbm_.b.shape, rbm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Data_Vector_Aux = np.array(vecs.toarray(), dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLast epoch:ime per epoch: 99.01\ttotal time: 99.02 0 \ttime per epoch: 99.01\ttotal time: 99.02\n",
      "\tTraining finished\n",
      "\n",
      "\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rbm_.fit(test_Data_Vector_Aux, \n",
    "         method='CDK',\n",
    "         K=K,\n",
    "         lr=lr,\n",
    "         epochs=1,\n",
    "         batch_size=300,\n",
    "         plot_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLast epoch:ime per epoch: 2.83\ttotal time: 2.83 0 \ttime per epoch: 2.83\ttotal time: 2.83\n",
      "\tTraining finished\n",
      "\n",
      "\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rbm_.fit(test_Data_Vector_Aux, \n",
    "         method='vectorized_CDK',\n",
    "         K=K,\n",
    "         lr=0.01,\n",
    "         epochs=1,\n",
    "         batch_size=128,\n",
    "         plot_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch: 0 \ttime per epoch: 2.83\ttotal time: 2.84 1 \ttime per epoch: 3.01\ttotal time: 5.86 2 \ttime per epoch: 2.66\ttotal time: 8.53 3 \ttime per epoch: 2.64\ttotal time: 11.17 4 \ttime per epoch: 2.51\ttotal time: 13.68 5 \ttime per epoch: 2.53\ttotal time: 16.21 6 \ttime per epoch: 2.51\ttotal time: 18.73 7 \ttime per epoch: 2.59\ttotal time: 21.32 8 \ttime per epoch: 2.49\ttotal time: 23.82 9 \ttime per epoch: 2.55\ttotal time: 26.37 10 \ttime per epoch: 2.48\ttotal time: 28.86 11 \ttime per epoch: 2.61\ttotal time: 31.47 12 \ttime per epoch: 2.48\ttotal time: 33.96 13 \ttime per epoch: 2.55\ttotal time: 36.52 14 \ttime per epoch: 2.51\ttotal time: 39.03 15 \ttime per epoch: 2.61\ttotal time: 41.64 16 \ttime per epoch: 2.96\ttotal time: 44.60 17 \ttime per epoch: 2.97\ttotal time: 47.58 18 \ttime per epoch: 2.68\ttotal time: 50.28 19 \ttime per epoch: 2.80\ttotal time: 53.08 20 \ttime per epoch: 2.81\ttotal time: 55.90 21 \ttime per epoch: 2.82\ttotal time: 58.73 22 \ttime per epoch: 2.78\ttotal time: 61.51 23 \ttime per epoch: 2.81\ttotal time: 64.32 24 \ttime per epoch: 2.70\ttotal time: 67.03 25 \ttime per epoch: 2.88\ttotal time: 69.91 26 \ttime per epoch: 2.60\ttotal time: 72.51 27 \ttime per epoch: 2.80\ttotal time: 75.32 28 \ttime per epoch: 2.75\ttotal time: 78.07 29 \ttime per epoch: 2.76\ttotal time: 80.84 30 \ttime per epoch: 2.73\ttotal time: 83.58 31 \ttime per epoch: 2.79\ttotal time: 86.38 32 \ttime per epoch: 3.17\ttotal time: 89.55 33 \ttime per epoch: 3.42\ttotal time: 92.98 34 \ttime per epoch: 3.40\ttotal time: 96.40 35 \ttime per epoch: 3.30\ttotal time: 99.71 36 \ttime per epoch: 3.44\ttotal time: 103.16 37 \ttime per epoch: 3.73\ttotal time: 106.90 38 \ttime per epoch: 3.52\ttotal time: 110.43 39 \ttime per epoch: 3.59\ttotal time: 114.03 40 \ttime per epoch: 3.58\ttotal time: 117.61 41 \ttime per epoch: 3.82\ttotal time: 121.44 42 \ttime per epoch: 3.43\ttotal time: 124.88 43 \ttime per epoch: 3.75\ttotal time: 128.64 44 \ttime per epoch: 3.57\ttotal time: 132.21 45 \ttime per epoch: 3.62\ttotal time: 135.84 46 \ttime per epoch: 3.53\ttotal time: 139.37 47 \ttime per epoch: 3.74\ttotal time: 143.12 48 \ttime per epoch: 3.07\ttotal time: 146.19 49 \ttime per epoch: 2.82\ttotal time: 149.01 50 \ttime per epoch: 2.84\ttotal time: 151.86 51 \ttime per epoch: 3.10\ttotal time: 154.96 52 \ttime per epoch: 3.13\ttotal time: 158.11 53 \ttime per epoch: 2.59\ttotal time: 160.70 54 \ttime per epoch: 2.75\ttotal time: 163.46 55 \ttime per epoch: 2.60\ttotal time: 166.07 56 \ttime per epoch: 3.05\ttotal time: 169.12 57 \ttime per epoch: 3.92\ttotal time: 173.05 58 \ttime per epoch: 4.38\ttotal time: 177.44 59 \ttime per epoch: 3.25\ttotal time: 180.70 60 \ttime per epoch: 3.50\ttotal time: 184.21 61 \ttime per epoch: 3.56\ttotal time: 187.78 62 \ttime per epoch: 3.60\ttotal time: 191.38 63 \ttime per epoch: 2.91\ttotal time: 194.30 64 \ttime per epoch: 3.35\ttotal time: 197.65 65 \ttime per epoch: 3.12\ttotal time: 200.77 66 \ttime per epoch: 3.08\ttotal time: 203.86 67 \ttime per epoch: 3.17\ttotal time: 207.03 68 \ttime per epoch: 3.04\ttotal time: 210.08 69 \ttime per epoch: 2.84\ttotal time: 212.93 70 \ttime per epoch: 2.99\ttotal time: 215.93 71 \ttime per epoch: 2.92\ttotal time: 218.85 72 \ttime per epoch: 2.76\ttotal time: 221.61 73 \ttime per epoch: 2.78\ttotal time: 224.40 74 \ttime per epoch: 2.96\ttotal time: 227.36 75 \ttime per epoch: 3.17\ttotal time: 230.54 76 \ttime per epoch: 2.81\ttotal time: 233.36 77 \ttime per epoch: 2.87\ttotal time: 236.24 78 \ttime per epoch: 2.98\ttotal time: 239.23 79 \ttime per epoch: 2.70\ttotal time: 241.93 80 \ttime per epoch: 2.70\ttotal time: 244.64 81 \ttime per epoch: 2.59\ttotal time: 247.24 82 \ttime per epoch: 2.61\ttotal time: 249.85 83 \ttime per epoch: 2.79\ttotal time: 252.65 84 \ttime per epoch: 3.82\ttotal time: 256.48 85 \ttime per epoch: 3.16\ttotal time: 259.65 86 \ttime per epoch: 3.25\ttotal time: 262.91 87 \ttime per epoch: 2.79\ttotal time: 265.71 88 \ttime per epoch: 3.18\ttotal time: 268.89 89 \ttime per epoch: 3.62\ttotal time: 272.52 90 \ttime per epoch: 3.51\ttotal time: 276.04 91 \ttime per epoch: 3.05\ttotal time: 279.10 92 \ttime per epoch: 3.00\ttotal time: 282.10 93 \ttime per epoch: 2.93\ttotal time: 285.04 94 \ttime per epoch: 2.85\ttotal time: 287.90 95 \ttime per epoch: 2.59\ttotal time: 290.50 96 \ttime per epoch: 2.61\ttotal time: 293.12 97 \ttime per epoch: 2.64\ttotal time: 295.76 98 \ttime per epoch: 2.65\ttotal time: 298.42 99 \ttime per epoch: 2.76\ttotal time: 301.18 100 \ttime per epoch: 2.48\ttotal time: 303.67 101 \ttime per epoch: 2.63\ttotal time: 306.30 102 \ttime per epoch: 2.53\ttotal time: 308.84 103 \ttime per epoch: 2.58\ttotal time: 311.42 104 \ttime per epoch: 2.53\ttotal time: 313.96 105 \ttime per epoch: 2.60\ttotal time: 316.57 106 \ttime per epoch: 2.53\ttotal time: 319.10 107 \ttime per epoch: 3.21\ttotal time: 322.32 108 \ttime per epoch: 4.13\ttotal time: 326.46 109 \ttime per epoch: 4.20\ttotal time: 330.68 110 \ttime per epoch: 3.26\ttotal time: 333.95 111 \ttime per epoch: 3.47\ttotal time: 337.43 112 \ttime per epoch: 3.12\ttotal time: 340.56 113 \ttime per epoch: 3.24\ttotal time: 343.81 114 \ttime per epoch: 3.57\ttotal time: 347.38 115 \ttime per epoch: 3.65\ttotal time: 351.05 116 \ttime per epoch: 3.69\ttotal time: 354.75 117 \ttime per epoch: 3.48\ttotal time: 358.23 118 \ttime per epoch: 3.82\ttotal time: 362.05 119 \ttime per epoch: 3.70\ttotal time: 365.77 120 \ttime per epoch: 3.65\ttotal time: 369.43 121 \ttime per epoch: 3.64\ttotal time: 373.08 122 \ttime per epoch: 3.44\ttotal time: 376.52 123 \ttime per epoch: 3.54\ttotal time: 380.07 124 \ttime per epoch: 3.51\ttotal time: 383.59 125 \ttime per epoch: 3.32\ttotal time: 386.91 126 \ttime per epoch: 3.41\ttotal time: 390.34 127 \ttime per epoch: 3.30\ttotal time: 393.64 128 \ttime per epoch: 3.60\ttotal time: 397.26 129 \ttime per epoch: 3.46\ttotal time: 400.72 130 \ttime per epoch: 3.52\ttotal time: 404.25 131 \ttime per epoch: 4.07\ttotal time: 408.32 132 \ttime per epoch: 3.57\ttotal time: 411.91 133 \ttime per epoch: 3.27\ttotal time: 415.19 134 \ttime per epoch: 3.67\ttotal time: 418.87 135 \ttime per epoch: 3.49\ttotal time: 422.37 136 \ttime per epoch: 3.50\ttotal time: 425.87 137 \ttime per epoch: 3.42\ttotal time: 429.30 138 \ttime per epoch: 3.39\ttotal time: 432.71 139 \ttime per epoch: 3.43\ttotal time: 436.15 140 \ttime per epoch: 3.51\ttotal time: 439.67 141 \ttime per epoch: 3.48\ttotal time: 443.16 142 \ttime per epoch: 3.34\ttotal time: 446.50 143 \ttime per epoch: 3.49\ttotal time: 450.01 144 \ttime per epoch: 3.52\ttotal time: 453.54 145 \ttime per epoch: 3.42\ttotal time: 456.96 146 \ttime per epoch: 3.52\ttotal time: 460.49 147 \ttime per epoch: 3.60\ttotal time: 464.10 148 \ttime per epoch: 3.31\ttotal time: 467.43 149 \ttime per epoch: 3.55\ttotal time: 470.98 150 \ttime per epoch: 3.57\ttotal time: 474.56 151 \ttime per epoch: 3.66\ttotal time: 478.23 152 \ttime per epoch: 3.58\ttotal time: 481.82 153 \ttime per epoch: 3.84\ttotal time: 485.67 154 \ttime per epoch: 3.54\ttotal time: 489.22 155 \ttime per epoch: 3.74\ttotal time: 492.97 156 \ttime per epoch: 3.71\ttotal time: 496.69 157 \ttime per epoch: 3.18\ttotal time: 499.88 158 \ttime per epoch: 3.57\ttotal time: 503.46 159 \ttime per epoch: 3.64\ttotal time: 507.11 160 \ttime per epoch: 3.45\ttotal time: 510.58 161 \ttime per epoch: 3.63\ttotal time: 514.22 162 \ttime per epoch: 3.63\ttotal time: 517.86 163 \ttime per epoch: 3.49\ttotal time: 521.36 164 \ttime per epoch: 3.40\ttotal time: 524.76 165 \ttime per epoch: 3.73\ttotal time: 528.50 166 \ttime per epoch: 3.69\ttotal time: 532.20 167 \ttime per epoch: 3.73\ttotal time: 535.94 168 \ttime per epoch: 3.69\ttotal time: 539.63 169 \ttime per epoch: 3.61\ttotal time: 543.25 170 \ttime per epoch: 3.50\ttotal time: 546.76 171 \ttime per epoch: 3.66\ttotal time: 550.43 172 \ttime per epoch: 3.63\ttotal time: 554.07 173 \ttime per epoch: 3.57\ttotal time: 557.65 174 \ttime per epoch: 3.70\ttotal time: 561.35 175 \ttime per epoch: 3.38\ttotal time: 564.75 176 \ttime per epoch: 2.85\ttotal time: 567.61 177 \ttime per epoch: 2.54\ttotal time: 570.15 178 \ttime per epoch: 2.72\ttotal time: 572.88 179 \ttime per epoch: 2.59\ttotal time: 575.48 180 \ttime per epoch: 3.51\ttotal time: 579.00 181 \ttime per epoch: 3.47\ttotal time: 582.47 182 \ttime per epoch: 3.00\ttotal time: 585.49 183 \ttime per epoch: 2.64\ttotal time: 588.14 184 \ttime per epoch: 3.19\ttotal time: 591.33 185 \ttime per epoch: 3.60\ttotal time: 594.93"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch: 186 \ttime per epoch: 3.04\ttotal time: 597.98 187 \ttime per epoch: 2.77\ttotal time: 600.76 188 \ttime per epoch: 2.66\ttotal time: 603.43 189 \ttime per epoch: 2.88\ttotal time: 606.31 190 \ttime per epoch: 2.73\ttotal time: 609.04 191 \ttime per epoch: 2.68\ttotal time: 611.73 192 \ttime per epoch: 2.68\ttotal time: 614.41 193 \ttime per epoch: 2.60\ttotal time: 617.02 194 \ttime per epoch: 2.66\ttotal time: 619.68 195 \ttime per epoch: 2.73\ttotal time: 622.42 196 \ttime per epoch: 2.62\ttotal time: 625.05 197 \ttime per epoch: 2.66\ttotal time: 627.71 198 \ttime per epoch: 3.16\ttotal time: 630.88 199 \ttime per epoch: 2.66\ttotal time: 633.55 200 \ttime per epoch: 3.05\ttotal time: 636.61 201 \ttime per epoch: 3.00\ttotal time: 639.61 202 \ttime per epoch: 2.88\ttotal time: 642.51 203 \ttime per epoch: 2.62\ttotal time: 645.13 204 \ttime per epoch: 2.61\ttotal time: 647.75 205 \ttime per epoch: 2.84\ttotal time: 650.60 206 \ttime per epoch: 2.74\ttotal time: 653.34 207 \ttime per epoch: 2.94\ttotal time: 656.29 208 \ttime per epoch: 2.71\ttotal time: 659.00 209 \ttime per epoch: 2.74\ttotal time: 661.74 210 \ttime per epoch: 2.73\ttotal time: 664.47 211 \ttime per epoch: 3.02\ttotal time: 667.50 212 \ttime per epoch: 3.53\ttotal time: 671.04 213 \ttime per epoch: 3.72\ttotal time: 674.77 214 \ttime per epoch: 3.45\ttotal time: 678.23 215 \ttime per epoch: 3.74\ttotal time: 681.97 216 \ttime per epoch: 3.34\ttotal time: 685.33 217 \ttime per epoch: 2.87\ttotal time: 688.20 218 \ttime per epoch: 3.64\ttotal time: 691.86 219 \ttime per epoch: 2.65\ttotal time: 694.52 220 \ttime per epoch: 2.98\ttotal time: 697.51 221 \ttime per epoch: 3.09\ttotal time: 700.60 222 \ttime per epoch: 2.98\ttotal time: 703.58 223 \ttime per epoch: 3.08\ttotal time: 706.69 224 \ttime per epoch: 3.13\ttotal time: 709.82 225 \ttime per epoch: 3.25\ttotal time: 713.08 226 \ttime per epoch: 2.52\ttotal time: 715.61 227 \ttime per epoch: 2.62\ttotal time: 718.23 228 \ttime per epoch: 2.49\ttotal time: 720.73 229 \ttime per epoch: 2.51\ttotal time: 723.25 230 \ttime per epoch: 2.63\ttotal time: 725.88 231 \ttime per epoch: 2.60\ttotal time: 728.49 232 \ttime per epoch: 2.57\ttotal time: 731.06 233 \ttime per epoch: 2.58\ttotal time: 733.64 234 \ttime per epoch: 2.63\ttotal time: 736.28 235 \ttime per epoch: 2.82\ttotal time: 739.11 236 \ttime per epoch: 3.66\ttotal time: 742.77 237 \ttime per epoch: 3.25\ttotal time: 746.03 238 \ttime per epoch: 2.60\ttotal time: 748.63 239 \ttime per epoch: 2.67\ttotal time: 751.31 240 \ttime per epoch: 2.76\ttotal time: 754.07 241 \ttime per epoch: 2.45\ttotal time: 756.53 242 \ttime per epoch: 2.53\ttotal time: 759.07 243 \ttime per epoch: 2.48\ttotal time: 761.56 244 \ttime per epoch: 2.55\ttotal time: 764.11 245 \ttime per epoch: 2.43\ttotal time: 766.55 246 \ttime per epoch: 2.52\ttotal time: 769.07 247 \ttime per epoch: 2.44\ttotal time: 771.51 248 \ttime per epoch: 2.56\ttotal time: 774.07 249 \ttime per epoch: 2.48\ttotal time: 776.56 250 \ttime per epoch: 2.54\ttotal time: 779.11 251 \ttime per epoch: 2.44\ttotal time: 781.55 252 \ttime per epoch: 2.52\ttotal time: 784.07 253 \ttime per epoch: 2.44\ttotal time: 786.52 254 \ttime per epoch: 2.53\ttotal time: 789.05 255 \ttime per epoch: 2.58\ttotal time: 791.64 256 \ttime per epoch: 2.79\ttotal time: 794.43 257 \ttime per epoch: 2.91\ttotal time: 797.34 258 \ttime per epoch: 2.73\ttotal time: 800.08 259 \ttime per epoch: 2.87\ttotal time: 802.96 260 \ttime per epoch: 2.67\ttotal time: 805.64 261 \ttime per epoch: 2.92\ttotal time: 808.56 262 \ttime per epoch: 2.72\ttotal time: 811.29 263 \ttime per epoch: 2.68\ttotal time: 813.98 264 \ttime per epoch: 2.59\ttotal time: 816.57 265 \ttime per epoch: 2.90\ttotal time: 819.48 266 \ttime per epoch: 2.68\ttotal time: 822.17 267 \ttime per epoch: 2.80\ttotal time: 824.98 268 \ttime per epoch: 2.75\ttotal time: 827.73 269 \ttime per epoch: 2.98\ttotal time: 830.72 270 \ttime per epoch: 2.88\ttotal time: 833.60 271 \ttime per epoch: 2.74\ttotal time: 836.35 272 \ttime per epoch: 3.22\ttotal time: 839.58 273 \ttime per epoch: 3.35\ttotal time: 842.93 274 \ttime per epoch: 2.92\ttotal time: 845.87 275 \ttime per epoch: 2.84\ttotal time: 848.71 276 \ttime per epoch: 2.76\ttotal time: 851.48 277 \ttime per epoch: 2.81\ttotal time: 854.29 278 \ttime per epoch: 2.84\ttotal time: 857.14 279 \ttime per epoch: 2.76\ttotal time: 859.91 280 \ttime per epoch: 3.03\ttotal time: 862.94 281 \ttime per epoch: 3.13\ttotal time: 866.08 282 \ttime per epoch: 3.04\ttotal time: 869.12 283 \ttime per epoch: 3.00\ttotal time: 872.13 284 \ttime per epoch: 2.60\ttotal time: 874.74 285 \ttime per epoch: 2.74\ttotal time: 877.49 286 \ttime per epoch: 2.77\ttotal time: 880.26 287 \ttime per epoch: 2.79\ttotal time: 883.05 288 \ttime per epoch: 2.70\ttotal time: 885.75 289 \ttime per epoch: 2.71\ttotal time: 888.47 290 \ttime per epoch: 2.76\ttotal time: 891.23 291 \ttime per epoch: 2.69\ttotal time: 893.93 292 \ttime per epoch: 2.73\ttotal time: 896.66 293 \ttime per epoch: 2.75\ttotal time: 899.42 294 \ttime per epoch: 2.75\ttotal time: 902.18 295 \ttime per epoch: 2.55\ttotal time: 904.74 296 \ttime per epoch: 2.79\ttotal time: 907.53 297 \ttime per epoch: 3.19\ttotal time: 910.73 298 \ttime per epoch: 2.98\ttotal time: 913.72 299 \ttime per epoch: 2.87\ttotal time: 916.59 300 \ttime per epoch: 3.05\ttotal time: 919.65 301 \ttime per epoch: 2.90\ttotal time: 922.56 302 \ttime per epoch: 2.94\ttotal time: 925.51 303 \ttime per epoch: 2.81\ttotal time: 928.32 304 \ttime per epoch: 2.92\ttotal time: 931.25 305 \ttime per epoch: 2.95\ttotal time: 934.21 306 \ttime per epoch: 2.77\ttotal time: 936.99 307 \ttime per epoch: 2.62\ttotal time: 939.62 308 \ttime per epoch: 2.71\ttotal time: 942.34 309 \ttime per epoch: 2.60\ttotal time: 944.95 310 \ttime per epoch: 2.72\ttotal time: 947.68 311 \ttime per epoch: 2.96\ttotal time: 950.64 312 \ttime per epoch: 2.59\ttotal time: 953.24 313 \ttime per epoch: 2.79\ttotal time: 956.04 314 \ttime per epoch: 3.43\ttotal time: 959.49 315 \ttime per epoch: 2.90\ttotal time: 962.39 316 \ttime per epoch: 2.77\ttotal time: 965.17 317 \ttime per epoch: 2.96\ttotal time: 968.13 318 \ttime per epoch: 2.85\ttotal time: 970.99 319 \ttime per epoch: 3.05\ttotal time: 974.04 320 \ttime per epoch: 2.51\ttotal time: 976.55 321 \ttime per epoch: 2.67\ttotal time: 979.23 322 \ttime per epoch: 2.65\ttotal time: 981.88 323 \ttime per epoch: 2.65\ttotal time: 984.54 324 \ttime per epoch: 2.66\ttotal time: 987.21 325 \ttime per epoch: 2.64\ttotal time: 989.85 326 \ttime per epoch: 2.59\ttotal time: 992.44 327 \ttime per epoch: 2.72\ttotal time: 995.17 328 \ttime per epoch: 2.73\ttotal time: 997.90 329 \ttime per epoch: 3.10\ttotal time: 1001.01 330 \ttime per epoch: 2.55\ttotal time: 1003.58 331 \ttime per epoch: 2.79\ttotal time: 1006.37 332 \ttime per epoch: 2.52\ttotal time: 1008.89 333 \ttime per epoch: 2.68\ttotal time: 1011.57 334 \ttime per epoch: 2.61\ttotal time: 1014.19 335 \ttime per epoch: 2.92\ttotal time: 1017.12 336 \ttime per epoch: 2.66\ttotal time: 1019.78 337 \ttime per epoch: 2.80\ttotal time: 1022.59 338 \ttime per epoch: 2.64\ttotal time: 1025.24 339 \ttime per epoch: 2.92\ttotal time: 1028.17 340 \ttime per epoch: 2.78\ttotal time: 1030.95 341 \ttime per epoch: 2.71\ttotal time: 1033.67 342 \ttime per epoch: 2.65\ttotal time: 1036.32 343 \ttime per epoch: 2.70\ttotal time: 1039.03 344 \ttime per epoch: 2.61\ttotal time: 1041.65 345 \ttime per epoch: 2.74\ttotal time: 1044.39 346 \ttime per epoch: 2.60\ttotal time: 1047.00 347 \ttime per epoch: 2.56\ttotal time: 1049.57 348 \ttime per epoch: 2.67\ttotal time: 1052.24 349 \ttime per epoch: 2.57\ttotal time: 1054.81 350 \ttime per epoch: 2.63\ttotal time: 1057.45 351 \ttime per epoch: 2.52\ttotal time: 1059.97 352 \ttime per epoch: 2.61\ttotal time: 1062.59 353 \ttime per epoch: 2.54\ttotal time: 1065.14 354 \ttime per epoch: 2.60\ttotal time: 1067.75 355 \ttime per epoch: 2.52\ttotal time: 1070.27 356 \ttime per epoch: 2.59\ttotal time: 1072.86 357 \ttime per epoch: 2.52\ttotal time: 1075.39 358 \ttime per epoch: 2.59\ttotal time: 1077.99 359 \ttime per epoch: 2.53\ttotal time: 1080.53 360 \ttime per epoch: 2.60\ttotal time: 1083.14 361 \ttime per epoch: 2.55\ttotal time: 1085.69 362 \ttime per epoch: 2.61\ttotal time: 1088.31 363 \ttime per epoch: 2.51\ttotal time: 1090.82 364 \ttime per epoch: 2.59\ttotal time: 1093.42 365 \ttime per epoch: 2.51\ttotal time: 1095.93 366 \ttime per epoch: 2.60\ttotal time: 1098.53 367"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLast epoch:poch: 2.52\ttotal time: 1101.06 368 \ttime per epoch: 2.63\ttotal time: 1103.69 369 \ttime per epoch: 2.52\ttotal time: 1106.21 370 \ttime per epoch: 2.59\ttotal time: 1108.81 371 \ttime per epoch: 2.57\ttotal time: 1111.38 372 \ttime per epoch: 3.08\ttotal time: 1114.47 373 \ttime per epoch: 2.60\ttotal time: 1117.08 374 \ttime per epoch: 2.53\ttotal time: 1119.61 375 \ttime per epoch: 2.69\ttotal time: 1122.30 376 \ttime per epoch: 2.55\ttotal time: 1124.86 377 \ttime per epoch: 2.58\ttotal time: 1127.45 378 \ttime per epoch: 2.54\ttotal time: 1129.99 379 \ttime per epoch: 2.59\ttotal time: 1132.59 380 \ttime per epoch: 2.54\ttotal time: 1135.13 381 \ttime per epoch: 2.62\ttotal time: 1137.75 382 \ttime per epoch: 2.52\ttotal time: 1140.28 383 \ttime per epoch: 2.59\ttotal time: 1142.87 384 \ttime per epoch: 2.60\ttotal time: 1145.48 385 \ttime per epoch: 2.69\ttotal time: 1148.18 386 \ttime per epoch: 3.02\ttotal time: 1151.21 387 \ttime per epoch: 2.78\ttotal time: 1154.00 388 \ttime per epoch: 2.71\ttotal time: 1156.71 389 \ttime per epoch: 2.72\ttotal time: 1159.44 390 \ttime per epoch: 2.83\ttotal time: 1162.27 391 \ttime per epoch: 2.73\ttotal time: 1165.02 392 \ttime per epoch: 2.70\ttotal time: 1167.72 393 \ttime per epoch: 2.66\ttotal time: 1170.39 394 \ttime per epoch: 2.52\ttotal time: 1172.91 395 \ttime per epoch: 2.58\ttotal time: 1175.49 396 \ttime per epoch: 2.49\ttotal time: 1177.99 397 \ttime per epoch: 2.56\ttotal time: 1180.55 398 \ttime per epoch: 2.51\ttotal time: 1183.07 399 \ttime per epoch: 2.54\ttotal time: 1185.62 400 \ttime per epoch: 2.48\ttotal time: 1188.11 401 \ttime per epoch: 2.54\ttotal time: 1190.65 402 \ttime per epoch: 2.49\ttotal time: 1193.15 403 \ttime per epoch: 2.49\ttotal time: 1195.65 404 \ttime per epoch: 2.56\ttotal time: 1198.21 405 \ttime per epoch: 2.46\ttotal time: 1200.68 406 \ttime per epoch: 2.57\ttotal time: 1203.25 407 \ttime per epoch: 2.48\ttotal time: 1205.74 408 \ttime per epoch: 2.56\ttotal time: 1208.30 409 \ttime per epoch: 2.48\ttotal time: 1210.79 410 \ttime per epoch: 2.80\ttotal time: 1213.59 411 \ttime per epoch: 2.44\ttotal time: 1216.04 412 \ttime per epoch: 2.56\ttotal time: 1218.60 413 \ttime per epoch: 2.51\ttotal time: 1221.12 414 \ttime per epoch: 2.54\ttotal time: 1223.67 415 \ttime per epoch: 2.54\ttotal time: 1226.21 416 \ttime per epoch: 2.62\ttotal time: 1228.84 417 \ttime per epoch: 2.55\ttotal time: 1231.40 418 \ttime per epoch: 2.60\ttotal time: 1234.00 419 \ttime per epoch: 2.52\ttotal time: 1236.52 420 \ttime per epoch: 2.59\ttotal time: 1239.12 421 \ttime per epoch: 2.56\ttotal time: 1241.69 422 \ttime per epoch: 2.56\ttotal time: 1244.25 423 \ttime per epoch: 2.48\ttotal time: 1246.74 424 \ttime per epoch: 2.60\ttotal time: 1249.35 425 \ttime per epoch: 2.48\ttotal time: 1251.83 426 \ttime per epoch: 2.59\ttotal time: 1254.43 427 \ttime per epoch: 2.49\ttotal time: 1256.92 428 \ttime per epoch: 2.58\ttotal time: 1259.50 429 \ttime per epoch: 2.50\ttotal time: 1262.01 430 \ttime per epoch: 2.56\ttotal time: 1264.58 431 \ttime per epoch: 2.48\ttotal time: 1267.07 432 \ttime per epoch: 2.52\ttotal time: 1269.59 433 \ttime per epoch: 2.58\ttotal time: 1272.18 434 \ttime per epoch: 2.74\ttotal time: 1274.92 435 \ttime per epoch: 2.67\ttotal time: 1277.60 436 \ttime per epoch: 2.49\ttotal time: 1280.09 437 \ttime per epoch: 2.57\ttotal time: 1282.67 438 \ttime per epoch: 2.51\ttotal time: 1285.19 439 \ttime per epoch: 2.54\ttotal time: 1287.73 440 \ttime per epoch: 2.50\ttotal time: 1290.24 441 \ttime per epoch: 2.58\ttotal time: 1292.83 442 \ttime per epoch: 2.50\ttotal time: 1295.34 443 \ttime per epoch: 2.53\ttotal time: 1297.88 444 \ttime per epoch: 2.65\ttotal time: 1300.53 445 \ttime per epoch: 2.58\ttotal time: 1303.12 446 \ttime per epoch: 2.50\ttotal time: 1305.63 447 \ttime per epoch: 2.55\ttotal time: 1308.18 448 \ttime per epoch: 2.48\ttotal time: 1310.67 449 \ttime per epoch: 2.72\ttotal time: 1313.40 450 \ttime per epoch: 2.77\ttotal time: 1316.18 451 \ttime per epoch: 2.82\ttotal time: 1319.00 452 \ttime per epoch: 2.84\ttotal time: 1321.85 453 \ttime per epoch: 3.39\ttotal time: 1325.25 454 \ttime per epoch: 3.28\ttotal time: 1328.53 455 \ttime per epoch: 3.29\ttotal time: 1331.83 456 \ttime per epoch: 3.21\ttotal time: 1335.05 457 \ttime per epoch: 3.34\ttotal time: 1338.40 458 \ttime per epoch: 3.25\ttotal time: 1341.66 459 \ttime per epoch: 3.37\ttotal time: 1345.03 460 \ttime per epoch: 3.21\ttotal time: 1348.24 461 \ttime per epoch: 3.27\ttotal time: 1351.52 462 \ttime per epoch: 3.29\ttotal time: 1354.82 463 \ttime per epoch: 3.17\ttotal time: 1358.00 464 \ttime per epoch: 3.28\ttotal time: 1361.28 465 \ttime per epoch: 3.26\ttotal time: 1364.55 466 \ttime per epoch: 3.32\ttotal time: 1367.88 467 \ttime per epoch: 3.25\ttotal time: 1371.13 468 \ttime per epoch: 3.27\ttotal time: 1374.42 469 \ttime per epoch: 3.21\ttotal time: 1377.64 470 \ttime per epoch: 3.32\ttotal time: 1380.96 471 \ttime per epoch: 3.22\ttotal time: 1384.19 472 \ttime per epoch: 3.33\ttotal time: 1387.53 473 \ttime per epoch: 3.19\ttotal time: 1390.73 474 \ttime per epoch: 3.55\ttotal time: 1394.29 475 \ttime per epoch: 3.81\ttotal time: 1398.11 476 \ttime per epoch: 3.33\ttotal time: 1401.45 477 \ttime per epoch: 3.22\ttotal time: 1404.68 478 \ttime per epoch: 3.50\ttotal time: 1408.19 479 \ttime per epoch: 3.34\ttotal time: 1411.54 480 \ttime per epoch: 3.34\ttotal time: 1414.89 481 \ttime per epoch: 3.23\ttotal time: 1418.13 482 \ttime per epoch: 3.30\ttotal time: 1421.44 483 \ttime per epoch: 3.23\ttotal time: 1424.68 484 \ttime per epoch: 3.37\ttotal time: 1428.05 485 \ttime per epoch: 3.24\ttotal time: 1431.30 486 \ttime per epoch: 3.34\ttotal time: 1434.64 487 \ttime per epoch: 3.25\ttotal time: 1437.91 488 \ttime per epoch: 3.34\ttotal time: 1441.26 489 \ttime per epoch: 3.27\ttotal time: 1444.54 490 \ttime per epoch: 3.23\ttotal time: 1447.77 491 \ttime per epoch: 3.30\ttotal time: 1451.09 492 \ttime per epoch: 3.24\ttotal time: 1454.34 493 \ttime per epoch: 3.30\ttotal time: 1457.65 494 \ttime per epoch: 3.25\ttotal time: 1460.92 495 \ttime per epoch: 3.33\ttotal time: 1464.26 496 \ttime per epoch: 3.24\ttotal time: 1467.51 497 \ttime per epoch: 3.48\ttotal time: 1471.00 498 \ttime per epoch: 3.29\ttotal time: 1474.30 499 \ttime per epoch: 3.41\ttotal time: 1477.72 499 \ttime per epoch: 3.41\ttotal time: 1477.72\n",
      "\tTraining finished\n",
      "\n",
      "\n",
      "Wall time: 24min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rbm_.fit(test_Data_Vector_Aux, \n",
    "         method='vectorized_CDK',\n",
    "         K=K,\n",
    "         lr=0.01,\n",
    "         epochs=500,\n",
    "         batch_size=128,\n",
    "         plot_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530,)\n"
     ]
    }
   ],
   "source": [
    "word = codec.encode_onehot(\"Josh\")\n",
    "print(word.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(530,) (530,)\n"
     ]
    }
   ],
   "source": [
    "x_hat, x_hat_p = rbm_.sample_visible_from_visible(word, n_gibbs=2000)\n",
    "print(x_hat.shape, x_hat_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr??t?$$$$\n"
     ]
    }
   ],
   "source": [
    "fW = codec.decode(x_hat)\n",
    "print(fW)\n",
    "# for i in range(10):\n",
    "#     x_hat1,x_hat_p1 = rbm_.sample_visible_from_visible(x_hat, n_gibbs=2000)\n",
    "#     print(codec.decode(x_hat1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
